{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204aa198",
   "metadata": {},
   "source": [
    "# Parallel HAVOK Analysis of a Lorenz System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, SSHCluster\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pysindy as ps\n",
    "import control\n",
    "import control.matlab\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "import time\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e329ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_type = 'jupyter'\n",
    "#cluster_type = 'command_line'\n",
    "\n",
    "if cluster_type == 'jupyter':\n",
    "    \n",
    "    cluster = SSHCluster(\n",
    "        [\"10.67.22.44\",\"10.67.22.117\",\"10.67.22.156\"],\n",
    "        connect_options={\"known_hosts\": None}\n",
    "    )\n",
    "    \n",
    "    client = Client(cluster)\n",
    "    \n",
    "else: client = Client(\"10.67.22.44:8786\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e810bf",
   "metadata": {},
   "source": [
    "### Lorenz data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e18017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz(t,y,sig,rho,beta):\n",
    "    dx = sig*(y[1] - y[0])\n",
    "    dy = y[0]*(rho - y[2]) - y[1]\n",
    "    dz = y[0]*y[1] - beta*y[2]\n",
    "    return [dx,dy,dz]\n",
    "\n",
    "solver = sp.integrate.solve_ivp(fun=lambda t, y: lorenz(t,y,10,28,8/3),\n",
    "                                 t_span=[0,1500.1], t_eval=np.arange(0,1500.1,0.001), y0=[-8,8,27], method='LSODA', \n",
    "                                 dense_output=False,rtol=1e-18,atol=1e-22)\n",
    "\n",
    "data_ts = solver.y.T\n",
    "data_ts = data_ts[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ff95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving into common folder\n",
    "\n",
    "n_partitions = 10\n",
    "l=100\n",
    "len_data = len(data_ts)-l\n",
    "\n",
    "for i in range(n_partitions):\n",
    "    data_p = data_ts[i*int(len_data/n_partitions):(i+1)*int(len_data/n_partitions)+100]\n",
    "    data_p.tofile('DATASET/Lorenz/data1M/data1M.{}.csv'.format(i+1), sep = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ac5d1",
   "metadata": {},
   "source": [
    "### HAVOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7be96e",
   "metadata": {},
   "source": [
    "#### Train import\n",
    "In this case the whole dataset is saved in `n_partitions` files but only a fraction is loaded into a Dask bag and used as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966f25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 6\n",
    "\n",
    "x_b = db.from_sequence(['DATASET/Lorenz/data1M/data1M.{}.csv'.format(i+1) for i in range(n_train)]).map(np.loadtxt)\n",
    "x_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b5b8f",
   "metadata": {},
   "source": [
    "#### Hankel matrix\n",
    "The first step of the HAVOK analysis consists of the division of the time series into sliding windows of length `l` and the creation of an Hankel matrix `H`. Since data is partitioned, it is convenient to create an Hankel matrix for every chunk with the condition that the components of each $H_i$ are smoothly connected i.e. the last row of $H_i$ must repeat most of the values contained in the first row of $H_{i+1}$. In this way the concatenation of all of the $H_i$ results into a tall and skinny Hankel matrix.<br>\n",
    "In order to have a simpler algorithm, data has been saved in advance in a way that this condition is verified (the last `l` data contained in each partition are the first data of the subsequent one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hankel(x_ts):\n",
    "    l=100\n",
    "    H = np.zeros((len(x_ts),l))\n",
    "    for i in range(len(x_ts)-l): H[i,:] = x_ts[i:l+i]\n",
    "    return H\n",
    "\n",
    "H = x_b.map(Hankel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51077209",
   "metadata": {},
   "source": [
    "#### Parallel SVD\n",
    "`H` is a tall and skinny matrix so we can perform the parallel SVD. In this case `U` is a matrix with the same dimensions of `H` but in order to perform the HAVOK analysis only the first `r` columns of it are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,Vt = parallel_SVD(H)\n",
    "\n",
    "r = 15\n",
    "u = np.concatenate(np.array(U[:,:,:r]),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801aacbd",
   "metadata": {},
   "source": [
    "#### Sparse Regression\n",
    "The sparse regression is performed locally using a method from `pySindy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.001\n",
    "time = np.arange(0,len(v)*dt,dt)\n",
    "\n",
    "differentiation_method = ps.FiniteDifference(order=2)\n",
    "feature_library = ps.PolynomialLibrary(degree=1)\n",
    "optimizer = ps.STLSQ(threshold=0.02)\n",
    "\n",
    "model = ps.SINDy(\n",
    "    differentiation_method=differentiation_method,\n",
    "    feature_library=feature_library,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "model.fit(u,t=time)\n",
    "\n",
    "M = model.coefficients()\n",
    "M = M[:,1:r+1]\n",
    "A = M[:r-1,:r-1]\n",
    "B = M[:r-1,r-1]\n",
    "\n",
    "df = pd.DataFrame(np.round(M))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacc0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "\n",
    "divnorm=colors.TwoSlopeNorm(vmin=np.min(A), vcenter=0., vmax=np.max(A))\n",
    "cax = ax.matshow(A, cmap= plt.get_cmap('PiYG'), norm=divnorm)\n",
    "fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac597e7",
   "metadata": {},
   "source": [
    "#### Integration of the linear model\n",
    "Using `A` and `B` and knowing the forcing term, the linear model can be integrated with the `control.StateSpace` method and compared with the embedded time series.<br>\n",
    "This is basically a numerical integration of a time series, so the computation can be done separately for each partition using the first row of each $U_i$ as initial conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33195b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.reshape(B,(r-1,1)) # control.StateSpace requires B with shape (r-1,1)\n",
    "sys = control.StateSpace(A,B,np.eye(r-1),0*B)\n",
    "result = u.map(lambda x: control.matlab.lsim(sys,x[:len(x),-1],np.arange(0,len(x)*dt,dt),x[0,:-1]))\\\n",
    "            .map(extract_Y).compute()\n",
    "\n",
    "y = np.concatenate(result,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9589b9",
   "metadata": {},
   "source": [
    "As one can see, the linear model perfectly describes the embedded time series. It is also evident that there is a correlation between the forcing term and the switching of the lobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (16,8))\n",
    "ax[0].plot(time[:50000],u[:50000,0],c='black',label='embedded time series')\n",
    "ax[0].plot(time[:50000],y[:50000,0],c='red',label='linear model',lw=1)\n",
    "ax[0].set_ylabel('u1',rotation=0)\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].plot(time[:50000],u[:50000,-1],c='black',lw=1)\n",
    "ax[1].set_ylabel('f',rotation=0)\n",
    "ax[1].set_xlabel('time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb940f51",
   "metadata": {},
   "source": [
    "#### Online prediction\n",
    "Since `A` and `B` are constant, once they have been computed using a training set, they can be used to integrate the rest of the dataset to make predictions about the lobe switching. Still, the integration requires the advance knowledge of the forcing term but this can be calculated by convoluting `V` with a slinding window of length `l` of the incoming data.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rest of the data into a Dask bag\n",
    "\n",
    "n_test = n_partitions - n_train\n",
    "test_b = db.from_sequence(['DATASET/Lorenz/data1M/data1M.{}.csv'.format(n_train+i+1) for i in range(n_test)])\\\n",
    "            .map(np.loadtxt)\n",
    "test_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution(x,V1,q,r):\n",
    "    U = np.zeros((len(x)-100,r))\n",
    "    for i in range(len(x)-100):\n",
    "        U[i,:] = np.dot(x[i:i+q],V1.T)\n",
    "    U = U[:,:r]\n",
    "    return U\n",
    "\n",
    "def Normalize(u_conv,S,r):\n",
    "    for i in range(r): u_conv[:,i] = u_conv[:,i]/S[i]\n",
    "    return u_conv\n",
    "   \n",
    "def extract_Y(M):\n",
    "    Y = M[:][0]\n",
    "    return Y\n",
    "\n",
    "V1 = Vt[:r,:]\n",
    "u_conv = test_b.map(lambda x: Convolution(x,V1,100,r)).map(lambda x: Normalize(x,S,r))\n",
    "\n",
    "sys_conv = control.StateSpace(A,B,np.eye(r-1),0*B)\n",
    "result = u_conv.map(lambda x: control.matlab.lsim(sys_conv,x[:len(x),-1],np.arange(0,len(x)*dt,dt),x[0,:-1]))\\\n",
    "            .map(extract_Y).compute()\n",
    "\n",
    "y_pred = np.concatenate(result,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67293ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1, figsize = (16,8))\n",
    "ax[0].plot(time[:50000],y_pred[:50000,0],c='black')\n",
    "ax[0].set_ylabel('u1',rotation=0)\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].plot(time[:50000],u_conv[:50000,r-1],c='black',lw=1)\n",
    "ax[1].set_ylabel('f',rotation=0)\n",
    "ax[1].set_xlabel('time [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b8289c",
   "metadata": {},
   "source": [
    "By setting a threshold in the forcing term it is possible to predict the chaotic behaviour of the Lorenz system i.e. the lobe switching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 500\n",
    "thresh = 0.0019\n",
    "mask = np.abs(u[:,-1]) > thresh\n",
    "\n",
    "i = 0\n",
    "prec = i\n",
    "while i < len(mask) - skip:\n",
    "    if mask[i] == True: \n",
    "        mask[i:i+skip] = [True for i in range(skip)]\n",
    "        i += skip\n",
    "    i += 1\n",
    "\n",
    "not_mask = [not x for x in mask]\n",
    "\n",
    "u_lin = np.copy(u_conv[:,0])\n",
    "u_lin[mask] = np.nan\n",
    "u_for = np.copy(u_conv[:,0])\n",
    "u_for[not_mask] = np.nan\n",
    "\n",
    "ur_lin = np.copy(u_conv[:,-1])\n",
    "ur_lin[mask] = np.nan\n",
    "ur_for = np.copy(u_conv[:,-1])\n",
    "ur_for[not_mask] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(16,8))\n",
    "ax[0].plot(time[:50000],u_lin[:50000],c='black',lw=1)\n",
    "ax[0].plot(time[:50000],u_for[:50000],c='red',lw=1)\n",
    "ax[0].axhline(0,lw=0.5,c=\"dimgrey\")\n",
    "ax[0].set_ylabel('u1',rotation=0)\n",
    "ax[1].plot(time[:50000],ur_lin[:50000],c='black',lw=1)\n",
    "ax[1].plot(time[:50000],ur_for[:50000],c='red',lw=1)\n",
    "ax[1].axhline(thresh_r,lw=0.5,c=\"darkred\",ls='--')\n",
    "ax[1].axhline(-thresh_r,lw=0.5,c=\"darkred\",ls='--')\n",
    "ax[1].set_ylabel('f',rotation=0)\n",
    "ax[1].set_xlabel('time [s]',rotation=0)\n",
    "ax[1].set_ylim(-0.025,0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0021c0",
   "metadata": {},
   "source": [
    "### Closing session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfd5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
